{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importation et exploration du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_20newsgroups(subset='all')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compliqué d'effectuer une analyse descriptive avec le dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension du dataset : 18846\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dimension de data : {len(data.data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target_names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separation du dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, x_test, y_train, y_test = train_test_split(data.data, data.target, \n",
    "                                                    train_size=1000, test_size=250, \n",
    "                                                    shuffle=True, stratify=data.target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorisation avec Tf-idf\n",
    "Objectif : Transformer les mots, ou phrases en vecteurs de nombres qui peuvent être utilisés comme entrées pour mon modèle d'apprentissage automatique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "x_test_tfidf = tfidf_vectorizer.transform(x_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### implementation du support vector machin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(gamma='auto', kernel='linear', probability=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "classif_model_tfidf = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto',probability=True)    \n",
    "classif_model_tfidf.fit(X_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13,  1,  6,  6, 13, 12, 17, 12, 14,  5, 13, 17, 10, 17,  4,  1, 18,\n",
       "       10, 12,  3, 10,  2,  1,  1,  6,  1,  6, 14,  6,  8,  5, 11,  4, 13,\n",
       "        8,  2,  6, 12,  4,  9,  6, 18,  8,  5,  4, 14, 15,  3, 11, 13, 14,\n",
       "        4, 12,  6, 17, 16,  5, 19, 15,  0, 13, 15,  8, 13, 12, 16,  7,  9,\n",
       "        5,  0, 12, 16,  8,  8, 16, 18, 16, 12,  3, 13, 12, 15, 17, 10,  5,\n",
       "       10,  9, 16,  9,  3,  5,  0, 19,  1, 14,  7,  2, 13,  3,  1, 13,  2,\n",
       "       11, 16,  6, 12, 17, 12, 13,  4,  8, 14,  1,  9,  3,  0, 12,  3,  7,\n",
       "       19, 11, 12,  1, 10,  3,  0, 12,  8, 17, 14, 16,  9, 19,  6,  9,  8,\n",
       "        4,  3,  4,  1, 18, 15,  9,  9, 16, 15,  0, 12,  6, 11, 17,  3,  2,\n",
       "        6, 15, 11,  2,  4,  3,  1,  0, 15, 17, 14,  5,  5,  0,  7,  6,  9,\n",
       "        1, 17, 12,  3, 16, 11,  3, 12, 18, 17, 19,  3, 14, 15, 16, 15, 14,\n",
       "        1,  2, 10, 13,  2,  2,  7, 15,  6,  6,  2,  7, 15,  8,  8, 12,  6,\n",
       "        6, 11, 14, 13,  7, 15, 15,  8, 17, 14,  2,  8, 13, 15, 17,  1,  1,\n",
       "        7,  7,  2,  7,  3,  5,  8, 16, 10,  3,  9, 12, 18,  0, 14,  5, 12,\n",
       "       17,  7, 12, 12,  2, 15, 12,  9, 11,  7, 13, 15])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_tfidf = classif_model_tfidf.predict(x_test_tfidf)\n",
    "y_pred_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.82      0.75        11\n",
      "           1       0.80      0.62      0.70        13\n",
      "           2       0.89      0.62      0.73        13\n",
      "           3       0.54      0.54      0.54        13\n",
      "           4       0.77      0.77      0.77        13\n",
      "           5       0.56      0.69      0.62        13\n",
      "           6       0.67      0.46      0.55        13\n",
      "           7       0.69      0.69      0.69        13\n",
      "           8       0.91      0.77      0.83        13\n",
      "           9       1.00      0.92      0.96        13\n",
      "          10       1.00      1.00      1.00        13\n",
      "          11       0.85      0.85      0.85        13\n",
      "          12       0.42      0.77      0.54        13\n",
      "          13       0.71      0.77      0.74        13\n",
      "          14       0.79      0.85      0.81        13\n",
      "          15       0.63      0.92      0.75        13\n",
      "          16       0.50      0.58      0.54        12\n",
      "          17       0.83      0.77      0.80        13\n",
      "          18       0.60      0.30      0.40        10\n",
      "          19       1.00      0.33      0.50         9\n",
      "\n",
      "    accuracy                           0.71       250\n",
      "   macro avg       0.74      0.70      0.70       250\n",
      "weighted avg       0.74      0.71      0.71       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation d'une fonction de nettoyage des caractéres indésirables \n",
    "def clean_text(text):\n",
    "    clean_text = text.replace('\\n','')\n",
    "    clean_text = clean_text.replace('\\t','') \n",
    "    return clean_text\n",
    "\n",
    "X_train_pre = [clean_text(news) for news in X_train]\n",
    "x_test_pre = [clean_text(news) for news in x_test]\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_pre_tfidf = tfidf_vectorizer.fit_transform(X_train_pre)\n",
    "x_test_pre_tfidf = tfidf_vectorizer.transform(x_test_pre)\n",
    "\n",
    "classif_model_pre_tfidf = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto',probability=True)    \n",
    "classif_model_pre_tfidf.fit(X_train_pre_tfidf,y_train)\n",
    "y_pred_pre_tfidf = classif_model_pre_tfidf.predict(x_test_pre_tfidf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Effectuons une analyse de la décomposition latente de Dirichlet (LDA) sur les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=20)\n",
    "lda.fit(X_train_tfidf)\n",
    "y_pred_lda = lda.transform(x_test_tfidf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### les mots représentatifs de chacun des clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 mots majoritairement représentant le cluster 0 : \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'TfidfVectorizer' object has no attribute 'get_feature_names_out'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-5ac71577f751>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtopic\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'10 mots majoritairement représentant le cluster {index} : '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtfidf_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtopic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-5ac71577f751>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtopic\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'10 mots majoritairement représentant le cluster {index} : '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtfidf_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtopic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TfidfVectorizer' object has no attribute 'get_feature_names_out'"
     ]
    }
   ],
   "source": [
    "for index,topic in enumerate(lda.components_):\n",
    "    print(f'10 mots majoritairement représentant le cluster {index} : ')\n",
    "    print([tfidf_vectorizer.get_feature_names_out()[i] for i in topic.argsort()[-10:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.7937137765773566e-05"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "\n",
    "y_pred_clusters = []\n",
    "for pred in y_pred_lda:\n",
    "  y_pred_clusters.append(np.argmax(pred))\n",
    "\n",
    "adjusted_rand_score(y_test, y_pred_clusters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
